{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Robots among Humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Name: LGTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maxine Liu\n",
    "- Roja Immanni\n",
    "- Zachary Barnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which classification algorithm can learn to best predict Robots among Humans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is obtained from here: https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Data Manipulations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, \\\n",
    "roc_auc_score, f1_score\n",
    "import imblearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from rfpimp import *\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# For plotting\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 5.75 s, total: 21.5 s\n",
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logs = pd.read_csv('https://facebookbids.s3.us-east-2.amazonaws.com/bids.csv')\n",
    "users = pd.read_csv('https://raw.githubusercontent.com/zs-barnes/Robot_or_not/master/data/train.csv',\n",
    "                    error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are no direct features derived for the data, we came up with a list of features based on the problem context. \n",
    "\n",
    "Following is the list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total Bid count\n",
    "- Total Auctions\n",
    "- Average bids per auction\n",
    "- Average time-gap between bids per auction\n",
    "- Minimum time-gap between bids per auction\n",
    "- Merchandise Type\n",
    "- Unique devices\n",
    "- Avergae bids per Device\n",
    "- Average bids per Country\n",
    "- Avergae bids per IP\n",
    "- Average bids per URL\n",
    "- Unique countries\n",
    "- Unique Ips\n",
    "- Distinct Ips per auction\n",
    "- Distinct Countries per auction\n",
    "- Distinct Devices per auction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the feature hypothesis from the logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the data by extracting required features from the corresponding logs data\n",
    "    \n",
    "    Input: Users data for which the features need to be extracted from the logs data\n",
    "    output: Users data with important features\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.merge(data, logs, on='bidder_id', how='left')\n",
    "    \n",
    "    \n",
    "    # Derive categorical features based on whether a user ever bid for certain categories\n",
    "    data.loc[(data.merchandise.isin(['auto parts','clothing','furniture'])),'merchandise_flag'] =1\n",
    "    data['merchandise_flag'].fillna(0, inplace=True)\n",
    "    \n",
    "    data = data.groupby(['bidder_id','outcome']).agg({'bid_id':'count', 'auction':'nunique',\n",
    "                                                          'device':'nunique', 'ip':'nunique',\n",
    "                                                          'url':'nunique','country':'nunique',\n",
    "                                                         'merchandise_flag':'mean'}).reset_index()\n",
    "    \n",
    "    \n",
    "    # Replaceing all the NA values with zero becuase in this case NA means user never involved in that certain \n",
    "    # bid. Hence zero\n",
    "    data.loc[(data.auction!=0),'bids_per_auction'] = data.loc[\n",
    "        (data.auction!=0),'bid_id']/data.loc[(data.auction!=0),'auction'] \n",
    "    data['bids_per_auction'].fillna(0, inplace=True)\n",
    "\n",
    "    data.loc[(data.device!=0),'bids_per_device'] = data.loc[\n",
    "        (data.device!=0),'bid_id']/data.loc[(data.device!=0),'device'] \n",
    "    data['bids_per_device'].fillna(0, inplace=True)\n",
    "\n",
    "    data.loc[(data.ip!=0),'bids_per_ip'] = data.loc[\n",
    "        (data.ip!=0),'bid_id']/data.loc[(data.ip!=0),'ip'] \n",
    "    data['bids_per_ip'].fillna(0, inplace=True)\n",
    "\n",
    "    data.loc[(data.url!=0),'bids_per_url'] = data.loc[\n",
    "        (data.url!=0),'bid_id']/data.loc[(data.url!=0),'url'] \n",
    "    data['bids_per_url'].fillna(0, inplace=True)\n",
    "\n",
    "    data.loc[(data.country!=0),'bids_per_country'] = data.loc[\n",
    "        (data.country!=0),'bid_id']/data.loc[(data.country!=0),'country'] \n",
    "    data['bids_per_country'].fillna(0, inplace=True)\n",
    "    \n",
    "    data.loc[(data.auction!=0),'ips_per_auction'] = data.loc[\n",
    "        (data.auction!=0),'ip']/data.loc[(data.auction!=0),'auction'] \n",
    "    data['ips_per_auction'].fillna(0, inplace=True)\n",
    "\n",
    "    data.loc[(data.auction!=0),'countries_per_auction'] = data.loc[\n",
    "        (data.auction!=0),'country']/data.loc[(data.auction!=0),'auction'] \n",
    "    data['countries_per_auction'].fillna(0, inplace=True)\n",
    "    \n",
    "    data.pop('bidder_id')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_X = prepare_data(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome                  0.0\n",
       "bid_id                   0.0\n",
       "auction                  0.0\n",
       "device                   0.0\n",
       "ip                       0.0\n",
       "url                      0.0\n",
       "country                  0.0\n",
       "merchandise_flag         0.0\n",
       "bids_per_auction         0.0\n",
       "bids_per_device          0.0\n",
       "bids_per_ip              0.0\n",
       "bids_per_url             0.0\n",
       "bids_per_country         0.0\n",
       "ips_per_auction          0.0\n",
       "countries_per_auction    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_X.isnull().sum()/len(users_X)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have any missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an unbalanced data. Hence we are choosing the metrics that are best on unbalanced datasets and with a capability to measure the separability between the classes. So our options are f1_weighted_score and roc_auc_score. Our North Star metric is weighted f1_score because of its ease of interpretability on imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance_split(X, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Given the entire data, this function splits the data into test and valid, maintaining a balanced split\n",
    "    across the classes\n",
    "    \n",
    "    Input: Total training data and test_size\n",
    "    Output: Train and test dataframes for X and y\n",
    "    \"\"\"\n",
    "\n",
    "    robots = X.loc[X.outcome==1]\n",
    "    humans = X.loc[X.outcome==0]\n",
    "\n",
    "    robots_train, robots_valid = train_test_split(robots, test_size=test_size)\n",
    "    humans_train, humans_valid = train_test_split(humans, test_size=test_size)\n",
    "\n",
    "    df_train = pd.concat([robots_train, humans_train], axis=0)\n",
    "    df_valid  = pd.concat([humans_valid, robots_valid], axis=0)\n",
    "\n",
    "    X_train = df_train\n",
    "    y_train = df_train['outcome']\n",
    "    X_train.pop('outcome')\n",
    "\n",
    "    X_valid = df_valid\n",
    "    y_valid = df_valid['outcome']\n",
    "    X_valid.pop('outcome')\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = class_balance_split(users_X, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the classes using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_instance = imblearn.over_sampling.SMOTE()\n",
    "X_train_smote, y_train_smote = rebalance_instance.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipelines():\n",
    "    \"\"\"\n",
    "    Creates pipeline for each of the following algorithms:\n",
    "    1. Logistic Regression\n",
    "    2. K-nearest Neighbors Regressor\n",
    "    3. Naive Bayes\n",
    "    4. Support Vector Machines\n",
    "    5. Random Forest\n",
    "    If appropriate, apply Normalizer before the algorithm.\n",
    "    Use default hyperparameters.\n",
    "    Input: None\n",
    "    Output: A list of all the pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    pipe_clf = Pipeline([\n",
    "                         ('norm', Normalizer()),\n",
    "                         ('clf', LogisticRegression(solver='lbfgs'))])\n",
    "    pipe_knn = Pipeline([('norm', Normalizer()),\n",
    "                         ('knn', KNeighborsClassifier())])\n",
    "    pipe_gnb = Pipeline([('gnb', GaussianNB())])\n",
    "    pipe_svm = Pipeline([('norm', Normalizer()),\n",
    "                         ('svc', SVC(probability=True))])\n",
    "    pipe_rf = Pipeline([('rf', RandomForestClassifier())])\n",
    "    \n",
    "    pipelines = [pipe_clf, pipe_knn, pipe_gnb, pipe_svm, pipe_rf]\n",
    "    \n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For LogisticRegression    :\n",
      " f1_weighted_score:0.8644987879091255, roc_auc_score:0.8884318125155822\n",
      "\n",
      "For KNeighborsClassifier  :\n",
      " f1_weighted_score:0.8874563273995487, roc_auc_score:0.8669907753677386\n",
      "\n",
      "For GaussianNB            :\n",
      " f1_weighted_score:0.8945453063181494, roc_auc_score:0.8413113936674147\n",
      "\n",
      "For SVC                   :\n",
      " f1_weighted_score:0.8462533932364826, roc_auc_score:0.8855646970830217\n",
      "\n",
      "For RandomForestClassifier:\n",
      " f1_weighted_score:0.9421375734004425, roc_auc_score:0.9116803789578659\n"
     ]
    }
   ],
   "source": [
    "# Train all the models\n",
    "pipelines = make_pipelines()\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "for pipe in pipelines:\n",
    "    name = pipe.steps[-1][1].__class__.__name__.split('.')[-1]\n",
    "    preds = pipe.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds, average='weighted')\n",
    "    probas = np.array([i[1] for i in pipe.predict_proba(X_valid)])\n",
    "    roc_auc = roc_auc_score(y_valid, probas)\n",
    "    print(f\"\\nFor {name:<22}:\\n f1_weighted_score:{f1}, roc_auc_score:{roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have RandomForestClassifier as the best performing one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of folds and samples\n",
    "\n",
    "cv=5\n",
    "n_iter=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_cv():\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1. Define Estimator\n",
    "    2. Define hyperparameter search space\n",
    "    3. Instantiate RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    estimator = RandomForestClassifier(random_state=2)\n",
    "    grid_params = dict(criterion=['gini', 'entropy'],\n",
    "                   n_estimators = [30, 50, 75, 100, 150, 200, 300, 500],\n",
    "                   min_samples_leaf = [1,2,3,4,5], max_features = [0.25, 0.3,0.35,0.4])\n",
    "\n",
    "    clf_random_cv = RandomizedSearchCV(estimator=estimator, \n",
    "                  param_distributions=grid_params,\n",
    "                  scoring='f1_weighted',\n",
    "                  cv=cv, n_iter=n_iter)\n",
    "\n",
    "    return clf_random_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_cv = make_random_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_leaf': 1, 'max_features': 0.4, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "fit_cv.fit(X=X_train_smote, y=y_train_smote)\n",
    "print(fit_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447597203277801"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_cv.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features=0.4, \n",
    "                                     criterion='gini', random_state=19).fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x223.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = importances(final_model, X_valid, y_valid, n_samples=-1)\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def k_fold_validation(n=5):\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    rebalance_instance = imblearn.over_sampling.SMOTE()\n",
    "    for i in range(n):\n",
    "        final_model = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, max_features=0.4, \n",
    "                                     criterion='entropy')\n",
    "        X_train, X_test, y_train, y_test = class_balance_split(users_X, test_size=0.2)\n",
    "        X_train_smote, y_train_smote = rebalance_instance.fit_sample(X_train, y_train)\n",
    "        final_model.fit(X_train_smote, y_train_smote)\n",
    "        y_pred = final_model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, y_pred,average='weighted'))\n",
    "        roc_auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"f1_scores: {f1_scores}\") \n",
    "    print(f\"roc_auc_scores: {roc_auc_scores}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores: [0.9392607881521832, 0.9358264756950219, 0.9328470140674513, 0.9375880384331903, 0.9435542674356965]\n",
      "roc_auc_scores: [0.7409623535277985, 0.8257292445774121, 0.7145350286711544, 0.8270381451009724, 0.7223884318125156]\n"
     ]
    }
   ],
   "source": [
    "k_fold_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "       ... \n",
       "2008    0.0\n",
       "2009    0.0\n",
       "2010    0.0\n",
       "2011    0.0\n",
       "2012    0.0\n",
       "Name: outcome, Length: 2013, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = users_X\n",
    "y = X['outcome']\n",
    "X.pop('outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, max_features=0.4,criterion='entropy')\n",
    "X_smote, y_smote = rebalance_instance.fit_sample(X, y)\n",
    "final_model.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForestClassifier performed the best on the dataset\n",
    "- Model predictions have a weighted f1_score of ~0.95 on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take-aways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is hard to interpret in terms of important features as the importance of the features seem to changes a lot with the final model chosen. Below listed are few parameters which consistently came out as the importance ones for the model\n",
    "- Count of unique devices, ips and countries that the user have bid from\n",
    "- Average number of bids made per device and ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to put this model into production, there should be 2-step verification process for the robots predicted as there are good number of Humans that are being predicted as Robots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
